# Abstract

This study investigates whether language selection in multilingual large language models (LLMs) affects output quality beyond translation accuracy. Through controlled testing of 21 semantically equivalent query pairs in Russian and English using Mistral AI's latest model, we discovered that language choice fundamentally alters communication strategy, information architecture, and user optimization rather than simply translating content. Russian responses averaged 21% shorter (527 vs 667 words) with 15% higher information density, optimizing for expert-level efficiency through hierarchical structure and minimal redundancy. English responses prioritized comprehensive coverage with extensive scaffolding for learners. Processing time paradoxically favored English (20.6s) over Russian (28.2s) despite shorter Russian outputs, suggesting tokenization complexity. Our findings challenge the "English-first" assumption in AI deployment and demonstrate that LLMs encode language-specific rhetorical conventions beyond lexical translation. We propose a framework for matching language selection to user expertise level and task context, with implications for multilingual AI system design, educational technology, and cross-cultural human-computer interaction.

**Keywords:** Large Language Models, Multilingual NLP, Communication Strategies, Information Architecture, User Experience, Mistral AI, Russian-English Comparison, LLM, AI

---

**Author:** Nikita Yampolski  
**Contact:** yampolski.net  
**Date:** January 2026  
**Model Tested:** Mistral AI mistral-large-latest  
**Institution/Affiliation:** ProductRocket.ch
